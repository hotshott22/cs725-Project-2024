{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0342ef33-bc5e-4166-aa7f-317518740f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d8ebe12a-39ca-496c-bc79-f67540836a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 14\n",
    "startDay = 350\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "45b6771e-75e5-4155-b9b4-1f7fef06e2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1919 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  d_1  d_2  d_3  d_4  ...  d_1904  d_1905  d_1906  d_1907  d_1908  \\\n",
       "0       CA    0    0    0    0  ...       1       3       0       1       1   \n",
       "1       CA    0    0    0    0  ...       0       0       0       0       0   \n",
       "2       CA    0    0    0    0  ...       2       1       2       1       1   \n",
       "\n",
       "   d_1909  d_1910  d_1911  d_1912  d_1913  \n",
       "0       1       3       0       1       1  \n",
       "1       1       0       0       0       0  \n",
       "2       1       0       1       1       1  \n",
       "\n",
       "[3 rows x 1919 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = pd.read_csv(\"sales_train_validation.csv\")\n",
    "dt.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "198a294c-9e8e-4a06-a5d6-d55f0cc809ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30490 entries, 0 to 30489\n",
      "Columns: 1919 entries, id to d_1913\n",
      "dtypes: int64(1913), object(6)\n",
      "memory usage: 446.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dt.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6cdf5514-b7e8-4abd-b236-b95e9faa75ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction_mem(df):\n",
    "    float_cols = [c for c in df if df[c].dtype == 'float64']\n",
    "    int_cols = [c for c in df if df[c].dtype in ['int64', 'int32']]\n",
    "    df[float_cols] = df[ float_cols].astype(np.float16)\n",
    "    df[int_cols] = df[int_cols].astype(np.int16)\n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5760a6ca-aa2b-4494-912c-c66a65f37231",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = reduction_mem(dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2403c40f-2ce8-4166-a5fc-bd84038050c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30490 entries, 0 to 30489\n",
      "Columns: 1919 entries, id to d_1913\n",
      "dtypes: int16(1913), object(6)\n",
      "memory usage: 112.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dt.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f7eb6950-bba9-4a88-b874-b86ee4351c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = dt.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "77d4e0a7-87f4-420d-a8ac-e069519891d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30480</th>\n",
       "      <th>30481</th>\n",
       "      <th>30482</th>\n",
       "      <th>30483</th>\n",
       "      <th>30484</th>\n",
       "      <th>30485</th>\n",
       "      <th>30486</th>\n",
       "      <th>30487</th>\n",
       "      <th>30488</th>\n",
       "      <th>30489</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d_351</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_352</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_353</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_354</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_355</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30490 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9      ... 30480  \\\n",
       "d_351     0     0     0     2     0     0     0    24     3     2  ...     0   \n",
       "d_352     0     0     0     0     0     0     0     9     0     2  ...     0   \n",
       "d_353     0     0     0     4     2     0     0     2     1     1  ...     0   \n",
       "d_354     0     1     0     2     0     0     0     7     1     0  ...     0   \n",
       "d_355     0     0     0     1     2     0     0     0     0     0  ...     0   \n",
       "\n",
       "      30481 30482 30483 30484 30485 30486 30487 30488 30489  \n",
       "d_351     9     1     0    11     0     0     1     0     0  \n",
       "d_352     5     4     0     8     0     1     2     0     0  \n",
       "d_353    15     2     0     3     0     1     2     0     0  \n",
       "d_354     5     1     0     3     0     0     0     0     0  \n",
       "d_355     7     1     0     1     0     1     1     0     0  \n",
       "\n",
       "[5 rows x 30490 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = dt[6 + startDay:]\n",
    "dt.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1cda8702-3024-436b-87da-eadd3f4490b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_data = pd.read_csv( 'calendar.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "98f0a86b-c26b-4d57-b5af-db29416bfa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "daysBeforeEvent = pd.DataFrame(np.zeros((1969,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a84c9340-b6b4-472c-8067-28cec24bfd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h3/lplmwndn2l1cw5q526nm0rlh0000gn/T/ipykernel_32651/452492889.py:3: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  daysBeforeEvent[0][x-1] = 1\n"
     ]
    }
   ],
   "source": [
    "for x,y in cal_data.iterrows():\n",
    "    if((pd.isnull(cal_data[\"event_name_1\"][x])) == False):\n",
    "           daysBeforeEvent[0][x-1] = 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "58f0300c-4cf9-4a4d-8d2e-5203a204058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del cal_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fc968d11-4d91-494f-b1f6-24d9e2caeb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "daysBeforeEventTest = daysBeforeEvent[1913:1941]\n",
    "#\"daysBeforeEvent\" will be used for training as a feature.\n",
    "daysBeforeEvent = daysBeforeEvent[startDay:1913]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8f2de5ab-f348-4a5d-974b-33f020ecec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "daysBeforeEvent.columns = [\"oneDayBeforeEvent\"]\n",
    "daysBeforeEvent.index = dt.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "24798376-58a4-4e2b-88ea-c255f0ea8e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([                  0,                   1,                   2,\n",
       "                         3,                   4,                   5,\n",
       "                         6,                   7,                   8,\n",
       "                         9,\n",
       "       ...\n",
       "                     30481,               30482,               30483,\n",
       "                     30484,               30485,               30486,\n",
       "                     30487,               30488,               30489,\n",
       "       'oneDayBeforeEvent'],\n",
       "      dtype='object', length=30491)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = pd.concat([dt, daysBeforeEvent], axis = 1)\n",
    "\n",
    "dt.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "df128b00-56db-4eff-b3eb-a7f8a4fd944f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "         0  1  2  3  4  5  6   7  8  9  ... 30481 30482 30483 30484 30485  \\\n",
      "d_351   0  0  0  2  0  0  0  24  3  2  ...     9     1     0    11     0   \n",
      "d_352   0  0  0  0  0  0  0   9  0  2  ...     5     4     0     8     0   \n",
      "d_353   0  0  0  4  2  0  0   2  1  1  ...    15     2     0     3     0   \n",
      "d_354   0  1  0  2  0  0  0   7  1  0  ...     5     1     0     3     0   \n",
      "d_355   0  0  0  1  2  0  0   0  0  0  ...     7     1     0     1     0   \n",
      "...    .. .. .. .. .. .. ..  .. .. ..  ...   ...   ...   ...   ...   ...   \n",
      "d_1909  1  1  1  0  1  0  1   4  0  0  ...     1     1     0     0     0   \n",
      "d_1910  3  0  0  1  2  0  0   6  0  0  ...     3     3     0     2     1   \n",
      "d_1911  0  0  1  3  2  2  0   3  0  2  ...     1     6     0     3     0   \n",
      "d_1912  1  0  1  7  2  0  1   2  0  0  ...     0     0     4     2     0   \n",
      "d_1913  1  0  1  2  4  0  1   1  0  2  ...     2     1     0     1     1   \n",
      "\n",
      "       30486 30487 30488 30489 oneDayBeforeEvent  \n",
      "d_351      0     1     0     0               0.0  \n",
      "d_352      1     2     0     0               1.0  \n",
      "d_353      1     2     0     0               0.0  \n",
      "d_354      0     0     0     0               0.0  \n",
      "d_355      1     1     0     0               0.0  \n",
      "...      ...   ...   ...   ...               ...  \n",
      "d_1909     0     1     1     0               0.0  \n",
      "d_1910     0     0     0     0               0.0  \n",
      "d_1911     0     0     3     0               0.0  \n",
      "d_1912     1     1     1     0               0.0  \n",
      "d_1913     0     0     3     0               0.0  \n",
      "\n",
      "[1563 rows x 30491 columns]\n",
      "Scaled Data:\n",
      "           0    1         2         3         4    5         6         7     8  \\\n",
      "d_351   0.0  0.0       0.0  0.133333       0.0  0.0       0.0  0.263736  0.15   \n",
      "d_352   0.0  0.0       0.0       0.0       0.0  0.0       0.0  0.098901   0.0   \n",
      "d_353   0.0  0.0       0.0  0.266667  0.222222  0.0       0.0  0.021978  0.05   \n",
      "d_354   0.0  0.2       0.0  0.133333       0.0  0.0       0.0  0.076923  0.05   \n",
      "d_355   0.0  0.0       0.0  0.066667  0.222222  0.0       0.0       0.0   0.0   \n",
      "...     ...  ...       ...       ...       ...  ...       ...       ...   ...   \n",
      "d_1909  0.2  0.2  0.166667       0.0  0.111111  0.0  0.333333  0.043956   0.0   \n",
      "d_1910  0.6  0.0       0.0  0.066667  0.222222  0.0       0.0  0.065934   0.0   \n",
      "d_1911  0.0  0.0  0.166667       0.2  0.222222  0.2       0.0  0.032967   0.0   \n",
      "d_1912  0.2  0.0  0.166667  0.466667  0.222222  0.0  0.333333  0.021978   0.0   \n",
      "d_1913  0.2  0.0  0.166667  0.133333  0.444444  0.0  0.333333  0.010989   0.0   \n",
      "\n",
      "               9  ...     30481     30482     30483     30484     30485  \\\n",
      "d_351   0.333333  ...  0.321429  0.111111       0.0  0.458333       0.0   \n",
      "d_352   0.333333  ...  0.178571  0.444444       0.0  0.333333       0.0   \n",
      "d_353   0.166667  ...  0.535714  0.222222       0.0     0.125       0.0   \n",
      "d_354        0.0  ...  0.178571  0.111111       0.0     0.125       0.0   \n",
      "d_355        0.0  ...      0.25  0.111111       0.0  0.041667       0.0   \n",
      "...          ...  ...       ...       ...       ...       ...       ...   \n",
      "d_1909       0.0  ...  0.035714  0.111111       0.0       0.0       0.0   \n",
      "d_1910       0.0  ...  0.107143  0.333333       0.0  0.083333  0.166667   \n",
      "d_1911  0.333333  ...  0.035714  0.666667       0.0     0.125       0.0   \n",
      "d_1912       0.0  ...       0.0       0.0  0.571429  0.083333       0.0   \n",
      "d_1913  0.333333  ...  0.071429  0.111111       0.0  0.041667  0.166667   \n",
      "\n",
      "           30486     30487     30488 30489 oneDayBeforeEvent  \n",
      "d_351        0.0  0.142857       0.0   0.0               0.0  \n",
      "d_352   0.083333  0.285714       0.0   0.0               1.0  \n",
      "d_353   0.083333  0.285714       0.0   0.0               0.0  \n",
      "d_354        0.0       0.0       0.0   0.0               0.0  \n",
      "d_355   0.083333  0.142857       0.0   0.0               0.0  \n",
      "...          ...       ...       ...   ...               ...  \n",
      "d_1909       0.0  0.142857  0.083333   0.0               0.0  \n",
      "d_1910       0.0       0.0       0.0   0.0               0.0  \n",
      "d_1911       0.0       0.0      0.25   0.0               0.0  \n",
      "d_1912  0.083333  0.142857  0.083333   0.0               0.0  \n",
      "d_1913       0.0       0.0      0.25   0.0               0.0  \n",
      "\n",
      "[1563 rows x 30491 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Updated Min-Max Scaler Implementation\n",
    "class MinMaxScalerCustom:\n",
    "    def __init__(self, feature_range=(0, 1)):\n",
    "        self.min_ = None\n",
    "        self.max_ = None\n",
    "        self.scale_ = None\n",
    "        self.min_range, self.max_range = feature_range\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"\n",
    "        Compute the min and max values for scaling.\n",
    "        \"\"\"\n",
    "        self.min_ = np.min(data, axis=0)  # Minimum value for each feature\n",
    "        self.max_ = np.max(data, axis=0)  # Maximum value for each feature\n",
    "        self.scale_ = self.max_ - self.min_\n",
    "\n",
    "    def transform(self, data):\n",
    "        \"\"\"\n",
    "        Scale the data to the feature range (min_range, max_range).\n",
    "        \"\"\"\n",
    "        if self.min_ is None or self.max_ is None:\n",
    "            raise ValueError(\"The scaler has not been fitted yet.\")\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        scale_adjusted = np.where(self.scale_ == 0, 1, self.scale_)\n",
    "        \n",
    "        # Scale data to 0-1\n",
    "        data_scaled = (data - self.min_) / scale_adjusted\n",
    "        # Scale data to the desired range\n",
    "        data_scaled = data_scaled * (self.max_range - self.min_range) + self.min_range\n",
    "        return data_scaled\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        \"\"\"\n",
    "        Fit the scaler to the data and then transform it.\n",
    "        \"\"\"\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "\n",
    "\n",
    "sc = MinMaxScalerCustom(feature_range=(0, 1))\n",
    "dt_scaled = sc.fit_transform(dt)\n",
    "\n",
    "# Print the original and scaled data\n",
    "print(\"Original Data:\\n\", dt)\n",
    "print(\"Scaled Data:\\n\", dt_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "410a6147-fe79-4d88-aa83-fbbdc04f8cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(timesteps, 1913 - startDay):\n",
    "    X_train.append(dt_scaled[i-timesteps:i])\n",
    "    y_train.append(dt_scaled[i][0:30490]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a4f46c83-c446-45a9-a7d8-72d7da1841f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dt_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "af2381f0-e486-48aa-8a91-64d0fa9b972e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1549, 14, 30491)\n",
      "(1549, 1563)\n"
     ]
    }
   ],
   "source": [
    "#Convert to np array to be able to feed the LSTM model\n",
    "X_train = np.array(X_train, dtype = 'float16')\n",
    "y_train = np.array(y_train, dtype = 'float16')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "17c3b97d-b284-4f32-8ef5-4be8755b6e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 1.007039536833763\n",
      "Epoch 2/20, Loss: 1.0006005787849426\n",
      "Epoch 3/20, Loss: 0.9994258749485015\n",
      "Epoch 4/20, Loss: 0.9987697786092758\n",
      "Epoch 5/20, Loss: 0.9978496676683426\n",
      "Epoch 6/20, Loss: 0.9964442044496536\n",
      "Epoch 7/20, Loss: 0.9948855066299438\n",
      "Epoch 8/20, Loss: 0.9928825354576111\n",
      "Epoch 9/20, Loss: 0.9907584106922149\n",
      "Epoch 10/20, Loss: 0.9887301462888718\n",
      "Epoch 11/20, Loss: 0.9865404093265533\n",
      "Epoch 12/20, Loss: 0.9845842534303665\n",
      "Epoch 13/20, Loss: 0.9823258292675018\n",
      "Epoch 14/20, Loss: 0.9804198235273361\n",
      "Epoch 15/20, Loss: 0.9787947487831116\n",
      "Epoch 16/20, Loss: 0.9769445097446442\n",
      "Epoch 17/20, Loss: 0.9753510880470276\n",
      "Epoch 18/20, Loss: 0.9737490236759185\n",
      "Epoch 19/20, Loss: 0.9724401897192001\n",
      "Epoch 20/20, Loss: 0.9711301320791245\n",
      "Prediction: tensor([[-0.0995, -0.0555,  0.0253,  ...,  0.0502,  0.2157, -0.1147]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# Define the BiLSTM Model\n",
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, sequence_length, output_size):\n",
    "        super(BiLSTMModel, self).__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        # Bidirectional LSTM Layer 1\n",
    "        self.lstm1 = nn.LSTM(input_size, 64, bidirectional=True, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        \n",
    "        # Bidirectional LSTM Layer 2\n",
    "        self.lstm2 = nn.LSTM(64 * 2, 16, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        # Fully connected output layer (adjusted to match target shape)\n",
    "        self.fc = nn.Linear(16 * 2, 1563)  # Adjusted to match target shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First LSTM Layer\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # Second LSTM Layer (get last output from the sequence)\n",
    "        x, _ = self.lstm2(x)\n",
    "        \n",
    "        # Only use the last output from the sequence\n",
    "        x = x[:, -1, :]  # Shape: (batch_size, 16 * 2)\n",
    "        \n",
    "        # Fully connected output layer\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Generate some example data (replace with your actual dataset)\n",
    "# For illustration, we'll use random data for X_train and y_train.\n",
    "X_train = np.random.randn(1000, 10, 20)  # Example shape (batch_size, sequence_length, input_size)\n",
    "y_train = np.random.randn(1000, 1563)    # Example target shape (batch_size, output_size)\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Define the model, loss function, and optimizer\n",
    "input_size = X_train.shape[2]   # Input feature size (20)\n",
    "sequence_length = X_train.shape[1]  # Sequence length (10)\n",
    "output_size = 1563  # Target size (1563)\n",
    "\n",
    "model = BiLSTMModel(input_size, sequence_length, output_size)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "# Save the trained model (optional)\n",
    "# torch.save(model.state_dict(), 'bilstm_model.pth')\n",
    "\n",
    "# Now you can test or use the model for predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_input = torch.tensor(np.random.randn(1, 10, 20), dtype=torch.float32)\n",
    "    prediction = model(sample_input)\n",
    "    print(\"Prediction:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "53752494-bd84-4334-9e91-beb20ab7d519",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs= dt[-timesteps:]\n",
    "inputs = sc.transform(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caf74e6-ecf2-4083-b5e9-db38b643b320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d622abe-6bfa-4842-ab68-fd84cb3e2ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ca1d31-2c39-4e87-a42c-7b5d909ce2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8222d52-d252-45d2-8bac-faf4400b8aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852fac76-9fe3-44ac-a3aa-ab26fc539345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
